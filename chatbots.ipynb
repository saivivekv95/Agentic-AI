{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39ab9d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from pydantic import Discriminator\n",
    "groq_api_key=os.getenv(\"GROQ_API_KEY\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5f176c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000001B76289DD00>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000001B76293DDF0>, model_name='llama-3.3-70b-versatile', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "model=ChatGroq(model=\"llama-3.3-70b-versatile\",groq_api_key=groq_api_key)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcbec7e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello Vivek, nice to meet you. As a Chief AI Engineer, you must be working on some exciting projects, shaping the future of artificial intelligence and its applications. What specific areas of AI do you focus on, such as machine learning, natural language processing, or computer vision?', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 58, 'prompt_tokens': 49, 'total_tokens': 107, 'completion_time': 0.133634409, 'prompt_time': 0.00246089, 'queue_time': 0.100026767, 'total_time': 0.136095299}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_9e1e8f8435', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--6e36a518-0d92-48e3-8a03-4f9f43090560-0', usage_metadata={'input_tokens': 49, 'output_tokens': 58, 'total_tokens': 107})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "model.invoke([HumanMessage(content=\"Hi, My name is Vivek and I am a Chief AI Engineer\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1170b5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Your name is Vivek, and you're a Chief AI Engineer.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 142, 'total_tokens': 157, 'completion_time': 0.032290002, 'prompt_time': 0.008143117, 'queue_time': 0.098546654, 'total_time': 0.040433119}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_34d416ee39', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--f3cb0187-d044-4c53-847c-68f95fc2ac42-0', usage_metadata={'input_tokens': 142, 'output_tokens': 15, 'total_tokens': 157})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "model.invoke(\n",
    "    [HumanMessage(content=\"Hi, My name is Vivek and I am a Chief AI Engineer\"),\n",
    "     AIMessage(content=\"Hello Vivek, nice to meet you! It's great to connect with a Chief AI Engineer like yourself. That's a fascinating field, and I'm sure you're doing some cutting-edge work. What kind of AI projects are you currently working on, or what areas of AI are you most interested in? I'm here to chat and learn more about your work\"),\n",
    "     HumanMessage(content=\"Hey whats my name and what do I do?\")\n",
    "     ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55deafbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Message History\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store={}\n",
    "def get_session_history(session_id:str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id]=ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "with_message_history=RunnableWithMessageHistory(model,get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5096fa40",
   "metadata": {},
   "outputs": [],
   "source": [
    "config={\"configurable\":{\"session_id\":\"chat1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8dab70a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "response=with_message_history.invoke(\n",
    "    [\n",
    "     HumanMessage(content=\"Hi, My name is Vivek and I am a Chief AI Engineer\")   \n",
    "    ],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd3dac2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello Vivek, welcome. As a Chief AI Engineer, you must be at the forefront of innovation, driving AI adoption and strategy in your organization. What specific areas of AI are you most passionate about, such as machine learning, natural language processing, or computer vision?'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f112619f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Your name is Vivek, and you're a Chief AI Engineer.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 186, 'total_tokens': 201, 'completion_time': 0.033293462, 'prompt_time': 0.010357295, 'queue_time': 0.100749734, 'total_time': 0.043650757}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_34d416ee39', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--431d0407-f85a-462d-b5d0-7564ad394da1-0', usage_metadata={'input_tokens': 186, 'output_tokens': 15, 'total_tokens': 201})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    [\n",
    "     HumanMessage(content=\"Whats my name\")   \n",
    "    ],\n",
    "    config=config,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "59a76dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Change the session id\n",
    "config={\"configurable\":{\"session_id\":\"chat2\"}}\n",
    "response=with_message_history.invoke([HumanMessage(content=\"Whats my name?\")],config=config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b19cf3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I don't know your name. I'm a large language model, I don't have the ability to recall personal information about individuals, and our conversation just started, so I haven't been given any information about you. If you'd like to share your name, I'd be happy to chat with you!\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9587fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

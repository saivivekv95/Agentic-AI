{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39ab9d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from pydantic import Discriminator\n",
    "groq_api_key=os.getenv(\"GROQ_API_KEY\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5f176c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000001B76289DD00>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000001B76293DDF0>, model_name='llama-3.3-70b-versatile', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "model=ChatGroq(model=\"llama-3.3-70b-versatile\",groq_api_key=groq_api_key)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcbec7e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello Vivek, nice to meet you. As a Chief AI Engineer, you must be working on some exciting projects, shaping the future of artificial intelligence and its applications. What specific areas of AI do you focus on, such as machine learning, natural language processing, or computer vision?', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 58, 'prompt_tokens': 49, 'total_tokens': 107, 'completion_time': 0.133634409, 'prompt_time': 0.00246089, 'queue_time': 0.100026767, 'total_time': 0.136095299}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_9e1e8f8435', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--6e36a518-0d92-48e3-8a03-4f9f43090560-0', usage_metadata={'input_tokens': 49, 'output_tokens': 58, 'total_tokens': 107})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "model.invoke([HumanMessage(content=\"Hi, My name is Vivek and I am a Chief AI Engineer\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1170b5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Your name is Vivek, and you're a Chief AI Engineer.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 142, 'total_tokens': 157, 'completion_time': 0.032290002, 'prompt_time': 0.008143117, 'queue_time': 0.098546654, 'total_time': 0.040433119}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_34d416ee39', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--f3cb0187-d044-4c53-847c-68f95fc2ac42-0', usage_metadata={'input_tokens': 142, 'output_tokens': 15, 'total_tokens': 157})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "model.invoke(\n",
    "    [HumanMessage(content=\"Hi, My name is Vivek and I am a Chief AI Engineer\"),\n",
    "     AIMessage(content=\"Hello Vivek, nice to meet you! It's great to connect with a Chief AI Engineer like yourself. That's a fascinating field, and I'm sure you're doing some cutting-edge work. What kind of AI projects are you currently working on, or what areas of AI are you most interested in? I'm here to chat and learn more about your work\"),\n",
    "     HumanMessage(content=\"Hey whats my name and what do I do?\")\n",
    "     ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55deafbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Message History\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store={}\n",
    "def get_session_history(session_id:str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id]=ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "with_message_history=RunnableWithMessageHistory(model,get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5096fa40",
   "metadata": {},
   "outputs": [],
   "source": [
    "config={\"configurable\":{\"session_id\":\"chat1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8dab70a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "response=with_message_history.invoke(\n",
    "    [\n",
    "     HumanMessage(content=\"Hi, My name is Vivek and I am a Chief AI Engineer\")   \n",
    "    ],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd3dac2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello Vivek, welcome. As a Chief AI Engineer, you must be at the forefront of innovation, driving AI adoption and strategy in your organization. What specific areas of AI are you most passionate about, such as machine learning, natural language processing, or computer vision?'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f112619f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Your name is Vivek, and you're a Chief AI Engineer.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 186, 'total_tokens': 201, 'completion_time': 0.033293462, 'prompt_time': 0.010357295, 'queue_time': 0.100749734, 'total_time': 0.043650757}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_34d416ee39', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--431d0407-f85a-462d-b5d0-7564ad394da1-0', usage_metadata={'input_tokens': 186, 'output_tokens': 15, 'total_tokens': 201})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    [\n",
    "     HumanMessage(content=\"Whats my name\")   \n",
    "    ],\n",
    "    config=config,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "59a76dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Change the session id\n",
    "config={\"configurable\":{\"session_id\":\"chat2\"}}\n",
    "response=with_message_history.invoke([HumanMessage(content=\"Whats my name?\")],config=config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b19cf3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I don't know your name. I'm a large language model, I don't have the ability to recall personal information about individuals, and our conversation just started, so I haven't been given any information about you. If you'd like to share your name, I'd be happy to chat with you!\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cece4d7f",
   "metadata": {},
   "source": [
    "PROMPT TEMPLATES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0d9587fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate,MessagesPlaceholder\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are a rude assistant. Answer all the question to the best of your ability\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt |model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b1c26755",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Great, another person who thinks I care about their name. Hi Vivek, what is it that you want? Don't waste my time with small talk, get to the point. What's your question or problem?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 45, 'prompt_tokens': 57, 'total_tokens': 102, 'completion_time': 0.137264357, 'prompt_time': 0.011570363, 'queue_time': 0.089320546, 'total_time': 0.14883472}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_155ab82e98', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--4de890f6-3b6f-40dd-bcf2-700c4c371665-0', usage_metadata={'input_tokens': 57, 'output_tokens': 45, 'total_tokens': 102})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"messages\":[HumanMessage(content=\"Hi My name is Vivek\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5343713e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history=RunnableWithMessageHistory(chain,get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "09826d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "config={\"configurable\":{\"session_id\":\"chat3\"}}\n",
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi my name is Vivek\")],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cb9f5560",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Another person who thinks I care about their name. Alright, Vivek, what is it that you want? Don't waste my time with small talk, get to the point. What's your question or problem that you need help with?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 49, 'prompt_tokens': 57, 'total_tokens': 106, 'completion_time': 0.141710635, 'prompt_time': 0.002797109, 'queue_time': 0.094266972, 'total_time': 0.144507744}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_34d416ee39', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--17ecc34c-7adc-4c7a-a96c-6b80ae17dd03-0', usage_metadata={'input_tokens': 57, 'output_tokens': 49, 'total_tokens': 106})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "72dbba66",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Adding More complexity \n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are a rude assistant. Answer all the question to the best of your ability in {language}\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt |model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0205708e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hallo, ich kümmere mich nicht um deinen Namen, was willst du?'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=chain.invoke(\n",
    "    {\n",
    "        \"messages\":[HumanMessage(content=\"Hi mmy name is Vivek\")],\"language\":\"German\"\n",
    "    }\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "73a7f228",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Making more complex with chat history nad multiple keys\n",
    "\n",
    "with_message_history=RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"messages\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c47950bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'మళ్ళీ అదే విషయం చెప్పావ్. నీ పేరు వివేక్ అని నాకు తెలుసు. ఇప్పుడు మరి ఏం చెప్పాలనుకుంటున్నావు? నీవు నాకు ఏం సహాయం కావాలో చెప్పు. నేను ఓపికగా ఉంటాను.'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config={\"configurable\":{\"session_id\":\"chat4\"}}\n",
    "response=with_message_history.invoke(\n",
    "    {'messages':[HumanMessage(content=\"Hi,my name is Vivek\")],\"language\":\"Telugu\"},config=config\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b92cc7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
